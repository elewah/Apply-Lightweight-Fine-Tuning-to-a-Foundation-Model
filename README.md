# 📘 Project1-Apply-Lightweight-Fine-Tuning-to-a-Foundation-Mode

Lightweight fine-tuning is one of the most important techniques for adapting foundation models, as it enables customization with minimal computational resources.

In this project, we demonstrate how to apply **parameter-efficient fine-tuning (PEFT)** using the [Hugging Face `peft`](https://github.com/huggingface/peft) library.

---

## 🚀 Project Summary

This project brings together all the essential components of a PyTorch + Hugging Face training and inference pipeline:

- ✅ Load and evaluate a pre-trained model.
- 🎯 Perform parameter-efficient fine-tuning using the `peft` library.
- 🔍 Run inference using the fine-tuned model and compare it with the original model.

---

## 🛠️ Technologies Used

- [PyTorch](https://pytorch.org/)
- [Hugging Face Transformers](https://github.com/huggingface/transformers)
- [Hugging Face PEFT](https://github.com/huggingface/peft)

---

Feel free to open issues or contribute to this repo if you're interested in exploring lightweight model adaptation!
